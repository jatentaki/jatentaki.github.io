---
title: "RayTran: 3D pose estimation and shape reconstruction of multiple objects from videos with ray-traced transformers"
collection: publications
permalink: /publication/24-03-2022
excerpt: 'We use attention to pool information from multiple posed input views in a global voxel representation. This allows for 3d object detection, shape reconstruction, novel view synthesis and more. A key trick is to exploit the image formation geometry to restrict the attention matrix, making the approach scalable and robust.'
date: 24-03-2022
venue: 'ECCV'
paperurl: 'https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700209.pdf'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
![image](../images/raytran-teaser.png)

> We propose a transformer-based neural network architecture for multi-object 3D reconstruction from RGB videos. It relies on two alternative ways to represent its knowledge: as a global 3D grid of features and an array of view-specific 2D grids. We progressively exchange information between the two with a dedicated bidirectional attention mechanism. We exploit knowledge about the image formation process to significantly sparsify the attention weight matrix, making our architecture feasible on current hardware, both in terms of memory and computation. We attach a DETR-style head on top of the 3D feature grid in order to detect the objects in the scene and to predict their 3D pose and 3D shape. Compared to previous methods, our architecture is single stage, end-to-end trainable, and it can reason holistically about a scene from multiple video frames without needing a brittle tracking step. We evaluate our method on the challenging Scan2CAD dataset, where we outperform (1) recent state-of-the-art methods for 3D object pose estimation from RGB videos; and (2) a strong alternative method combining Multi-view Stereo with RGB-D CAD alignment.